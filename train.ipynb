{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.rvae import RVAE\n",
    "from util.batch_loader import Batch\n",
    "from util.preprocess import Preprocess\n",
    "from util.parameter import Parameter\n",
    "from gensim.models import KeyedVectors\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model=KeyedVectors.load_word2vec_format('embedding.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt','r') as f:\n",
    "    data=f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "preprocess=Preprocess(embedding_model)\n",
    "input=preprocess.to_sequence(data)\n",
    "if not os.path.exists('embedding.npy'):\n",
    "    embedding=preprocess.embedding()\n",
    "    np.save('embedding',embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch generator and parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loader=Batch(input,0.7)\n",
    "params=Parameter(word_embed_size=300,encode_rnn_size=600,latent_variable_size=1000,\\\n",
    "            decode_rnn_size=600,vocab_size=preprocess.vocab_size,embedding_path='embedding.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model , optimizer and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RVAE(params)\n",
    "if not os.path.isfile('checkpoint.pth.tar'):\n",
    "    optimizer=Adam(model.learnable_parameters(), 5e-5)\n",
    "else:\n",
    "    checkpoint=torch.load('checkpoint.pth.tar')\n",
    "    optimizer=checkpoint['optimizer']\n",
    "    i=torch.load('i')\n",
    "    model.i=i\n",
    "\n",
    "train_step=model.trainer(optimizer)\n",
    "\n",
    "if os.path.exists('trained_rvae'):\n",
    "    model.load_state_dict(torch.load('trained_rvae'))\n",
    "use_cuda=torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model=model.cuda()\n",
    "ce_list=[]\n",
    "kld_list=[]\n",
    "coef_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RVAE (\n",
      "  (encoder): Encoder (\n",
      "    (highway): Highway (\n",
      "    )\n",
      "    (lstm): LSTM(300, 600, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (decoder): Decoder (\n",
      "    (lstm): LSTM(1300, 600, batch_first=True)\n",
      "    (fc): Linear (600 -> 18803)\n",
      "  )\n",
      "  (logvar): Linear (1200 -> 1000)\n",
      "  (mu): Linear (1200 -> 1000)\n",
      "  (embedding): Embedding (\n",
      "    (word_embed): Embedding(18803, 300)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch=batch_loader.test_next_batch(1)\n",
    "for j in range(100):\n",
    "    for i,batch in enumerate(batch_loader.train_next_batch(32)):\n",
    "        if i%51==0:\n",
    "            sample=next(test_batch)\n",
    "            print(' '.join([preprocess.index_to_word[i] for i in sample[0][0]]),'\\n')\n",
    "            sentence=model.sample(len(sample[0][0])+10,sample,use_cuda)\n",
    "            sentence=[preprocess.index_to_word[i] for i in sentence]\n",
    "            print(' '.join(sentence))\n",
    "            continue\n",
    "        ce,kld,coef=train_step(batch,0.2,use_cuda)\n",
    "        if i%50==0:\n",
    "            print('50 step: ce:{}, kld:{} '.format(ce,kld))\n",
    "            torch.save(model.state_dict(), 'trained_rvae')\n",
    "            save_checkpointe({\n",
    "            'optimizer':optimizer.state_dict(),\n",
    "            'i':model.i\n",
    "            })\n",
    "        if i%100==0:\n",
    "            print(model.i)\n",
    "        ce_list+=[ce.cpu().numpy()[0]]\n",
    "        kld_list+=[kld.cpu().numpy()[0]]\n",
    "        coef_list+=[coef]\n",
    "    print(\"epoch finish {}\".format(j))\n",
    "    np.save('ce',ce_list)\n",
    "    np.save('kld',kld_list)\n",
    "    np.save('coef',coef_list)\n",
    "    save_checkpointe({\n",
    "        'optimizer':optimizer.state_dict(),\n",
    "        'i':model.i\n",
    "    })\n",
    "    with open('status','w') as f:\n",
    "        f.write('echo {}'.format(j))\n",
    "    !gsutil cp trained_rvae ce.npy kld.npy coef.npy status checkpoint.pth.tar gs://rvae\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3]\n",
    "np.save('a.npy',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('a.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
